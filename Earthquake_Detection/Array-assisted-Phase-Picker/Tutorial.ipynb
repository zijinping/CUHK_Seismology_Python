{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Array-assisted Phase Picker (APP) Tutorial \n",
    "\n",
    "### (Jiang Y R, Ning J Y, 2019)\n",
    "\n",
    "#### Tutorial Script created by Jeremy Wong @2020.05.27\n",
    "\n",
    "Source Code and tutorial is written based on : https://github.com/baogegeJiang/Array-assisted-Phase-Picker\n",
    "\n",
    "Array-assisted Phase Picker is vector support machine, an trained model to conducts seismic arrival-time picking. The modified Array-assisted phase picker introduce futher packages ultilizing the output of the AI to conduct futher analysis. The trained model detect and locate the arrival of the P-arrival and S-arrival of the input seimsic traces.\n",
    "\n",
    "### Table of content\n",
    "* [1 - Demonstrate the Pre-trained Model](#first-bullet)\n",
    "    * [1.1 Import Pre-trained Model from genMV3.py](#1.1)\n",
    "    * [1.2 Import and organize data to feed the model](#1.2)\n",
    "    * [1.3 Plot and analysis the result ](#1.3)\n",
    "* [2 - Advance usage of Array-assisted Phase-picker](#second-bullet)\n",
    "    * [2.1 Prerequsite for the APP programme](#2.1)\n",
    "    * [2.2 Run APP](#2.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 - Demonstrate the Pre-trained Model <a class=\"anchor\" id=\"first-bullet\"></a>\n",
    "### 1.1 Import Pre-trained Model from genMV3.py <a class=\"anchor\" id=\"1.1\"></a>\n",
    "\n",
    "In the folllowing, the model is imported via the script genMV3.py and updated with the weights pretrained with noise and without noise as selected. \n",
    "\n",
    "   - 'modelP_320000_0-2-15-with', 'modelS_320000_0-2-15-with': \n",
    "         models trained with typical noise\n",
    "   - 'modelP_320000_100-2-15', 'modelS_320000_100-2-15':  \n",
    "         models trained without typical noise\n",
    "<figure>\n",
    "<img src=\"img/SVM.png\" height=70 />\n",
    "<figcaption> Figure 1. Model Architecture of PhaseNet [Figure 5, Zhu W. & Beroza G. C.]\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "A simplified illustration of a SVM. It is a nonlinear classifier. The orginal data are transform to higher dimension via kernal and are classified by the support vector. Detailed can be found in the paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/jeremy/opt/anaconda3/envs/seismo/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jeremy/opt/anaconda3/envs/seismo/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jeremy/opt/anaconda3/envs/seismo/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jeremy/opt/anaconda3/envs/seismo/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jeremy/opt/anaconda3/envs/seismo/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jeremy/opt/anaconda3/envs/seismo/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jeremy/opt/anaconda3/envs/seismo/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Input shape of the model :(None, 2000, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "#### Import Relevant Packages\n",
    "from keras.utils import plot_model\n",
    "\n",
    "\n",
    "### Import model from genMV3.py\n",
    "from genMV3 import genModel\n",
    " \n",
    "modelP = genModel()\n",
    "modelP.load_weights('modelP_320000_0-2-15-with')\n",
    "modelS = genModel()\n",
    "modelS.load_weights('modelS_320000_0-2-15-with')\n",
    "\n",
    "# show spec of the model\n",
    "print(\"Input shape of the model :\" + str(modelP.input_shape))\n",
    "# Plot the structure of the model (output: img/modelP.png)\n",
    "if False:               # Select True to plot the structure of the model\n",
    "    plot_model(modelP, \n",
    "               to_file=\"img/modelP.png\",\n",
    "               show_shapes=True,\n",
    "               show_layer_names=True,\n",
    "               rankdir=\"TB\", # TB - vertical plot; LR - horizontal plot\n",
    "               expand_nested=True, # whether to expand nested models into clusters\n",
    "               dpi=96)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Import and organize data to feed the model <a class=\"anchor\" id=\"1.2\"></a>\n",
    "\n",
    "1) The seismic data shall be organized in the following format to feed to the model:\n",
    "<center> <code> (n, 2000, 1, 3) </code> </center>\n",
    "\n",
    "   - n: data slices count\n",
    "   - 2000: sampling points in the time domain 40s, 50hz\n",
    "   - 3: components [E, N, Z]\n",
    "\n",
    "2) Preprocessing the data\n",
    "   - Filter the data with bandpass of [2 Hz - 15 Hz] \n",
    "\n",
    "   <code> st.filter(\"bandpass\", freqmin=2, freqmax=15) </code>\n",
    "\n",
    "   - Normalize the waveform using the following\n",
    "\n",
    "   `inputData /= inputData.std(axis=(1,2,3), keepdims=True)` \n",
    "\n",
    "3) Feed the model with the data\n",
    "\n",
    "   <code> probP = modelP.predict(inputData) </code>\n",
    "\n",
    "   <code> probS = modelS.predict(inputData) </code>\n",
    "\n",
    "Returns: Probabilities of P and S arrivals\n",
    "\n",
    "#### Import sample data from HKPS\n",
    "In the following, we will detect and locate the P and S arrival time of the recent local earthquakes in HK of the seismic data recorded by Po Shan Station. The data can be fetched using `obspy.clients.fdsn.Client`.\n",
    "\n",
    "Since the sampling of the seismic trace maybe different from 50 hz, we have to resample the trace into 50hz with lenght of 40 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Trace(s) in Stream:\n",
      "HK.HKPS..BHE | 2020-01-04T22:55:30.019500Z - 2020-01-04T22:56:09.994500Z | 40.0 Hz, 1600 samples\n",
      "HK.HKPS..BHN | 2020-01-04T22:55:30.019500Z - 2020-01-04T22:56:09.994500Z | 40.0 Hz, 1600 samples\n",
      "HK.HKPS..BHZ | 2020-01-04T22:55:30.019500Z - 2020-01-04T22:56:09.994500Z | 40.0 Hz, 1600 samples\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy import UTCDateTime\n",
    "\n",
    "verbose = True\n",
    "# Obtain data from HKPS station\n",
    "client = Client('IRIS')\n",
    "t1 = UTCDateTime(\"2020-01-04T22:55:30\")\n",
    "st = client.get_waveforms(\"HK\",\"HKPS\",\"\",\"BH*\", t1, t1 + 40)\n",
    "if verbose:\n",
    "    print(st)\n",
    "\n",
    "# resample, filter and normalize\n",
    "st.resample(50.0)\n",
    "st.filter(\"bandpass\", freqmin=2, freqmax=15)\n",
    "st.normalize()\n",
    "\n",
    "# Extract data from obspy.trace\n",
    "data = np.zeros((1,2000,1,3))\n",
    "for i in range(3):\n",
    "    data[0,:,0,i] = st[i].data\n",
    "\n",
    "\n",
    "### Feed to the model\n",
    "probP = modelP.predict(data)\n",
    "probS = modelS.predict(data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Plot and analysis the result  <a class=\"anchor\" id=\"1.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'st' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5187ec86f769>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'st' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_results(st,probP,probS):\n",
    "    # Plot stream with the probabilty of P ans S arrival predicted from the model\n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    ax = fig.add_subplot(411)\n",
    "    ax.plot(st[0].times(\"matplotlib\"), st[0].data)\n",
    "    ax.xaxis_date()\n",
    "    ax = fig.add_subplot(412)\n",
    "    ax.plot(st[0].times(\"matplotlib\"), st[1].data)\n",
    "    ax.xaxis_date()\n",
    "    ax = fig.add_subplot(413)\n",
    "    ax.plot(st[0].times(\"matplotlib\"), st[2].data)\n",
    "    ax.xaxis_date()\n",
    "    ax = fig.add_subplot(414)\n",
    "    ax.plot(st[0].times(\"matplotlib\"),probP[0,:,0,0])\n",
    "    ax.plot(st[0].times(\"matplotlib\"),probS[0,:,0,0])\n",
    "    ax.xaxis_date()\n",
    "    fig.autofmt_xdate()\n",
    "    plt.show()\n",
    "\n",
    "plot_results(st, probP, probS)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Advance usage of Array-assisted Phase-net <a class=\"anchor\" id=\"second-bullet\"></a>\n",
    "\n",
    "The developed version of he Phase Picker requires the following items to run the programme\n",
    "\n",
    "### 2.1 Prerequsite for the APP programme <a class=\"anchor\" id=\"2.1\"></a>\n",
    "\n",
    "#### 2.1.1 Station Information list file\n",
    "net  sta  component  long/ยบ  lat/ยบ  elevation/m  rms_of_lon  rms_of_lat\n",
    "\n",
    "`HK HKPS BH 104.55 31.00 0.0000 0.0000 0.0000`\n",
    "\n",
    "    ```\n",
    "    def generate_stationlist(st, stlst_file):\n",
    "    \"\"\" Generate station list from obspy.stream\n",
    "    \"\"\"\n",
    "        stlst = []\n",
    "        for tr in st:\n",
    "            stlst.append([tr.stats.network, tr.stats.station, tr.stats.channel,\n",
    "                          tr.stats.longtitude, tr.stats.latitude, tr.stats.elevation,\n",
    "                          0.0,0.0])\n",
    "        with open(stlst_file, \"w+\") as file:\n",
    "            for ls in stlst:\n",
    "                file.write(\" \".join(ls) + \"\\n\")\n",
    "    ```\n",
    "Generate station infomration list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['GD', 'DOG', 'BH', '113.723', '22.875', '59.0', '0.0', '0.0'], ['HK', 'HKPS', 'BH', '114.142', '22.2776', '196.3', '0.0', '0.0'], ['GD', 'HUD', 'BH', '113.227', '23.5164', '65.0', '0.0', '0.0'], ['GD', 'SHW', 'BH', '115.37', '22.7916', '15.0', '0.0', '0.0'], ['GD', 'XFJ', 'BH', '114.657', '23.7385', '101.0', '0.0', '0.0'], ['GD', 'XNH', 'BH', '113.034', '22.5697', '86.0', '0.0', '0.0'], ['GD', 'YGJ', 'BH', '111.954', '21.8581', '20.0', '0.0', '0.0'], ['GD', 'ZHH', 'BH', '113.566', '22.2706', '50.0', '0.0', '0.0'], ['HK', 'HKPS', 'BH', '114.142', '22.2776', '196.3', '0.0', '0.0'], ['HK', 'HKCD', 'HH', '114.26', '22.2092', '40.0', '0.0', '0.0'], ['HK', 'HKLK', 'HH', '114.211', '22.5139', '90.0', '0.0', '0.0'], ['HK', 'HKOC', 'HH', '114.174', '22.302', '29.0', '0.0', '0.0'], ['HK', 'HKPS', 'HH', '114.142', '22.2776', '196.3', '0.0', '0.0'], ['HK', 'HKTB', 'HH', '114.012', '22.4863', '4.0', '0.0', '0.0'], ['HK', 'HKYN', 'HH', '114.338', '22.3776', '87.0', '0.0', '0.0'], ['MO', 'DTS', 'EH', '113.568', '22.1595', '134.0', '0.0', '0.0']]\n",
      "Generated station_list \n"
     ]
    }
   ],
   "source": [
    "from obspy import read, Stream\n",
    "\n",
    "##### Station list generator\n",
    "def generate_stationlist(st, stlst_file):\n",
    "    \"\"\" Generate station list from obspy.stream\n",
    "    \"\"\"\n",
    "    stlst = []\n",
    "    _net, _sta, _com = \"\", \"\", \"\"\n",
    "    for tr in st:\n",
    "        # Remove deplicated entry\n",
    "        if _net==tr.stats.network and _sta==tr.stats.station and _com==tr.stats.channel[0:2]:\n",
    "            pass\n",
    "        else:\n",
    "            _net = tr.stats.network\n",
    "            _sta = tr.stats.station\n",
    "            _com = tr.stats.channel[0:2]\n",
    "\n",
    "            stlst.append([tr.stats.network, tr.stats.station, tr.stats.channel[0:2],\n",
    "                          str(tr.stats.sac.stlo), str(tr.stats.sac.stla), str(tr.stats.sac.stel),\n",
    "                          \"0.0\",\"0.0\"])\n",
    "    print(stlst)\n",
    "    # stlst = list(dict.fromkeys(stlst))\n",
    "    with open(stlst_file, \"w+\") as file:\n",
    "        for ls in stlst:\n",
    "            file.write(\" \".join(ls) + \"\\n\")\n",
    "    #print(\"Generated %s \" % stlst_file)\n",
    "\n",
    "\n",
    "# Read sac in a day to generate station list\n",
    "st_loc = \"/Users/jeremy/OneDrive - The Chinese University of Hong Kong/cu/academic/sources/program/seismology/tmp/2020/005\"\n",
    "stlist_file = \"station_list\"\n",
    "_st = read(st_loc + '/*')\n",
    "st = Stream()\n",
    "\n",
    "# Select list of channel only (exclude V.., L..)\n",
    "for chan in \"BH*\", \"HH*\",\"EH*\":\n",
    "    st += _st.select(channel=chan)\n",
    "\n",
    "# Gen station list\n",
    "generate_stationlist(st, stlist_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 File path function\n",
    "A funtion that return the sacfile name list according to the input (net, station, component, date).\n",
    "    - net is the network name(e. g. 'XX' )\n",
    "    - station is the station name(e. g. 'ABC' )\n",
    "    - comp is the component name(e. g. 'BHE' )\n",
    "    - YmdHMSJ is a dict contained date information(year, month, day, hour, minute, second, day num from the first day of the year)\n",
    "    (e. g. {'Y': '2019', 'm': '01', 'd': '01', 'H': '00', 'M': '01', 'S': '00', 'J': '001'}).\n",
    "   \n",
    "Some sac files naming convection consists of the stations' location code. The following code have modified of the sac naming convection for GD network stations and specific stations with loc.\n",
    "    ```\n",
    "    def FileName(net, station, comp, YmdHMSJ):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "                net - station network\n",
    "            station - station name\n",
    "               comp - station component\n",
    "            YmdHMSJ - dict of date\n",
    "        \"\"\"\n",
    "        sacFileNames = list()\n",
    "        c=comp[-1]\n",
    "        if c=='Z':\n",
    "            c='U'\n",
    "        \n",
    "        sacFileNames.append('data/'+net+'/'+station+'/'+net+'.'+YmdHMSJ['Y']+\\\n",
    "            YmdHMSJ['m']+YmdHMSJ['d']+'.'+station+'.'+c+'.SAC')\n",
    "            \n",
    "        # OR\n",
    "        if net in ['GD']:\n",
    "            loc = '_00'\n",
    "            sacFileNames.append(sac_dir+'/'+YmdHMSJ['Y']+'/'+YmdHMSJ['J']+'/'\\\n",
    "                                +YmdHMSJ['Y']+YmdHMSJ['J']+\"000000.00\"+'.'+station+'.'+comp+loc)\n",
    "        elif station == 'HKOC':\n",
    "            loc = '_10'\n",
    "            sacFileNames.append(sac_dir+'/'+YmdHMSJ['Y']+'/'+YmdHMSJ['J']+'/'\\\n",
    "                                +YmdHMSJ['Y']+YmdHMSJ['J']+\"000000.00\"+'.'+station+'.'+comp+loc)        \n",
    "        else:\n",
    "            sacFileNames.append(sac_dir+'/'+YmdHMSJ['Y']+'/'+YmdHMSJ['J']+'/'\\\n",
    "                                +YmdHMSJ['Y']+YmdHMSJ['J']+\"000000.00\"+'.'+station+'.'+comp)\n",
    "        return sacFileNames \n",
    "     ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Run APP <a class=\"anchor\" id=\"2.2\"></a>\n",
    "\n",
    "The code would run the phase detection using the `detecQuake.getStaL` and associate the detections using `detecQuake.associateSta`. \n",
    "\n",
    "The output of the association would use `tool.saveQuakeLs` to append the results in the `work directory` and plot the results using `detecQuake.plotResS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'h5py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e1a6f6b0b7ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import relavant package\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdetecQuake\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrainPSV2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrainPS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msacTool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/OneDrive - The Chinese University of Hong Kong/cu/academic/Final Year Project/ML/Array-assisted-Phase-Picker/detecQuake.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mobspy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msacTool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetDataByFileName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstaTimeMat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mglob\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/OneDrive - The Chinese University of Hong Kong/cu/academic/Final Year Project/ML/Array-assisted-Phase-Picker/sacTool.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mobspy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobspy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtaup\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTauPyModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/OneDrive - The Chinese University of Hong Kong/cu/academic/Final Year Project/ML/Array-assisted-Phase-Picker/tool.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minterpolate\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minterp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobspy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUTCDateTime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtaup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'h5py'"
     ]
    }
   ],
   "source": [
    "# import relavant package\n",
    "import os\n",
    "import detecQuake\n",
    "import trainPSV2 as trainPS\n",
    "import sacTool\n",
    "from obspy import UTCDateTime, read\n",
    "import tool\n",
    "from locate import locator\n",
    "\n",
    "##### sac file function\n",
    "def FileName(net, station, comp, YmdHMSJ):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "            net - station network\n",
    "        station - station name\n",
    "           comp - station component\n",
    "        YmdHMSJ - dict of date\n",
    "    \"\"\"\n",
    "    ### Data from external harddisk\n",
    "    #sac_dir='/Volumes/JW harddisk/Seismology/Data'\n",
    "    ### Sample data from the computer\n",
    "    sac_dir = '/Users/jeremy/OneDrive - The Chinese University of Hong Kong/cu/academic/sources/program/seismology/tmp'\n",
    "    sacFileNames = list()\n",
    "    c=comp[-1]\n",
    "    if c=='Z':\n",
    "        c='U'\n",
    "    \n",
    "    # Add location to specific stations\n",
    "    if net in ['GD']:\n",
    "        loc = '_00'\n",
    "        sacFileNames.append(sac_dir+'/'+YmdHMSJ['Y']+'/'+YmdHMSJ['J']+'/'\\\n",
    "                            +YmdHMSJ['Y']+YmdHMSJ['J']+\"000000.00\"+'.'+station+'.'+comp+loc)\n",
    "    elif station == 'HKOC':\n",
    "        loc = '_10'\n",
    "        sacFileNames.append(sac_dir+'/'+YmdHMSJ['Y']+'/'+YmdHMSJ['J']+'/'\\\n",
    "                            +YmdHMSJ['Y']+YmdHMSJ['J']+\"000000.00\"+'.'+station+'.'+comp+loc)        \n",
    "    else:\n",
    "        sacFileNames.append(sac_dir+'/'+YmdHMSJ['Y']+'/'+YmdHMSJ['J']+'/'\\\n",
    "                            +YmdHMSJ['Y']+YmdHMSJ['J']+\"000000.00\"+'.'+station+'.'+comp)\n",
    "    \n",
    "    #print(sacFileNames)\n",
    "    return sacFileNames\n",
    "\n",
    "\"\"\"/Users/jeremy/OneDrive - The Chinese University of Hong Kong/cu/academic/sources/program/seismology/tmp/2016/142\"\"\"\n",
    "\n",
    "            \n",
    "# Generate station list from sacfiles\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "workDir='/Users/jeremy/OneDrive - The Chinese University of Hong Kong/cu/academic/Final Year Project/ML/work/'# workDir: the dir to save the results\n",
    "staLstFile='station_list'#station list file\n",
    "bSec=UTCDateTime(2020,1,1).timestamp#begain date\n",
    "eSec=UTCDateTime(2020,1,14).timestamp#end date\n",
    "laL=[21, 24]#area: [min_latitude, max_latitude]\n",
    "loL=[110, 120]#area: [min_longitude, max_longitude]\n",
    "laN=35#subareas in latitude/the default is enough\n",
    "loN=35#subareas in longitude\n",
    "nameFunction=FileName# set to your own file path function\n",
    "\n",
    "#####no need to change ##########\n",
    "taupM=tool.quickTaupModel(modelFile='iaspTaupMat')# load pre-calculated travel time result to accelerate the computation speed of travel time \n",
    "modelL = [trainPS.loadModel('modelP_320000_100-2-15'),\\\n",
    "trainPS.loadModel('modelS_320000_100-2-15')]#load pre-trained model of P/S\n",
    "staInfos=sacTool.readStaInfos(staLstFile) #load station information stored in staLstFile\n",
    "aMat=sacTool.areaMat(laL,loL,laN,loN)#generate subareas according to laL,loL,laN,loN\n",
    "staTimeML= detecQuake.getStaTimeL(staInfos, aMat, taupM=taupM)#calculate the travel time  range between each station and each subarea\n",
    "quakeLs=list()# init the quakeLs to store results in memory\n",
    "\n",
    "for date in range(int(bSec),int(eSec),86400):\n",
    "    \n",
    "    date=UTCDateTime(float(date))\n",
    "    print('pick on ',date)\n",
    "    staL = detecQuake.getStaL(staInfos, aMat, staTimeML,\\\n",
    "        modelL, date, getFileName=nameFunction,\\\n",
    "        mode='norm',f=[2,15])\n",
    "    quakeLs.append(detecQuake.associateSta(staL, aMat, \\\n",
    "        staTimeML, timeR=10, maxDTime=3, N=1,locator=\\\n",
    "        locator(staInfos)))\n",
    "    '''\n",
    "    save:\n",
    "    result's in  workDir+'phaseLst'\n",
    "    result's waveform in  workDir+'output/'\n",
    "    result's plot picture in  workDir+'output/'\n",
    "    '''\n",
    "    tool.saveQuakeLs(quakeLs, workDir+'phaseLst')\n",
    "    tool.saveQuakeLWaveform(staL, quakeLs[-1], \\\n",
    "        matDir=workDir+'output/',\\\n",
    "            index0=-1500,index1=1500)\n",
    "    detecQuake.plotResS(staL,quakeLs[-1],outDir=workDir+'output/')\n",
    "    staL=[]# clear data  to save memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
